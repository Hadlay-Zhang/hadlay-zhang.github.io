---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<style>
  .publications-wrapper {
    max-width: 850px;
    width: 100%;
  }

  .publication-item {
    display: flex;
    gap: 2rem;
    margin-bottom: 3rem;
    align-items: flex-start;
  }

  .publication-image {
    flex: 0 0 33%;
    width: 33%;
  }

  .pub-img {
    width: 100%;
    height: auto;
    display: block;
    border-radius: 4px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
  }

  .publication-content {
    flex: 1;
    min-width: 0;
  }

  .publication-content h3 {
    margin-top: 0;
    margin-bottom: 0.3rem;
    font-size: 1.1em;
    color: var(--pub-color);
  }

  .publication-content p {
    margin: 0.2rem 0;
    line-height: 1.5;
  }

  .publication-content a {
    color: var(--pub-color);
    text-decoration: none;
  }

  .publication-content a:hover {
    text-decoration: underline;
  }

  :root {
    --pub-color: #0366d6;
  }

  html[data-theme="dark"] {
    --pub-color: #58a6ff;
  }
</style>

{% if site.author.googlescholar %}
<div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar
    profile</a>.</div>
<p><sup>*</sup> denotes equal contribution.</p>
{% endif %}

{% include base_path %}

<div class="publications-list publications-wrapper">

  <div class="publication-item">
    <div class="publication-image">
      <img src="/images/postergen.png" alt="PosterGen Framework" class="pub-img">
    </div>
    <div class="publication-content">
      <h3>PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs</h3>
      <p><strong>Zhilin Zhang</strong><sup>*</sup>, Xiang Zhang<sup>*</sup>, Jiaqi Wei, Yiwei Xu, Chenyu You</p>
      <p><em>Preprint</em></p>
      <p>
        <a href="https://arxiv.org/abs/2508.17188">paper</a>
        &nbsp;&nbsp;/&nbsp;&nbsp;
        <a href="https://y-research-sbu.github.io/PosterGen">website</a>
        &nbsp;&nbsp;/&nbsp;&nbsp;
        <a href="https://github.com/Y-Research-SBU/PosterGen">code</a>
        &nbsp;&nbsp;
        <img src="https://img.shields.io/github/stars/Y-Research-SBU/PosterGen" alt="GitHub stars"
          style="vertical-align: text-bottom;">
      </p>
    </div>
  </div>

  <div class="publication-item">
    <div class="publication-image">
      <img src="/images/OMniBAN.png" alt="OMniBAN Framework" class="pub-img">
    </div>
    <div class="publication-content">
      <h3>Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering</h3>
      <p><strong>Zhilin Zhang</strong>, Jie Wang, Zhanghao Qin, Ruiqi Zhu, Xiaoliang Gong</p>
      <p><em>IJCNN 2025</em></p>
      <p>
        <a href="https://ieeexplore.ieee.org/document/11228425">paper</a>
      </p>
    </div>
  </div>

  <div class="publication-item">
    <div class="publication-image">
      <img src="/images/ReID.png" alt="Person ReID Framework" class="pub-img">
    </div>
    <div class="publication-content">
      <h3>Enhancing Intra-Modality Compactness in Text-to-Image Person ReID</h3>
      <p>Zhanghao Qin, Hongming Zhang, <strong>Zhilin Zhang</strong>, Tianyu Wang, Hongtao Mao, Guangzhen Yao</p>
      <p><em>IJCNN 2025</em></p>
      <p>
        <a href="https://ieeexplore.ieee.org/document/11228976">paper</a>
      </p>
    </div>
  </div>

  <div class="publication-item">
    <div class="publication-image">
      <img src="/images/SentiXRL.png" alt="SentiXRL Framework" class="pub-img">
    </div>
    <div class="publication-content">
      <h3>SentiXRL: An advanced large language Model Framework for Multilingual Fine-Grained Emotion Classification in
        Complex Text Environment</h3>
      <p>Jie Wang, Yichen Wang, <strong>Zhilin Zhang</strong>, Jianhao Zeng, Kaidi Wang, Zhiyang Chen</p>
      <p><em>Preprint</em></p>
      <p>
        <a href="https://arxiv.org/abs/2411.18162">paper</a>
      </p>
    </div>
  </div>

  <div class="publication-item">
    <div class="publication-image">
      <img src="/images/VQA.png" alt="VQA Framework" class="pub-img">
    </div>
    <div class="publication-content">
      <h3>Enhanced Textual Feature Extraction for Visual Question Answering: A Simple Convolutional Approach</h3>
      <p><strong>Zhilin Zhang</strong>, Fangyu Wu</p>
      <p><em>CVCI 2025</em></p>
      <p>
        <a href="https://doi.org/10.1145/3744725.3744731">paper</a>
      </p>
    </div>
  </div>

</div>